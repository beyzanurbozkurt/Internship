{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11SuVQ05G6aR8XSFFjSQ1j51U039xf0lD","timestamp":1743065014259},{"file_id":"16ONbhCpBIugEus-0NDuEmNS9nSxDN36F","timestamp":1742992819930},{"file_id":"1AloRl52cNazasV63_aSOX8pyWzYBL42y","timestamp":1742976614638},{"file_id":"1Gz_dN7QsUktnnLowFZPOeJQuOHcQJxVl","timestamp":1736572404570},{"file_id":"1VN20JTr6VN3sFTy8LcodWdwCRNsDmbwG","timestamp":1736545982113},{"file_id":"1fwY7bWmE1J1ku19jcDf6SnRH4cRdIsph","timestamp":1736532704848},{"file_id":"1yvhzTmLnQnQMbpk1sLWg-rMmP7h_vETp","timestamp":1735912451525}],"authorship_tag":"ABX9TyPJkuNXZOcHhcLmByumFNFB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","\n","# File paths\n","train_csv_files = [\n","    'drive/My Drive/TIF/train_new/TIF_AUG_AU_SI_ver1_fold_0.csv',\n","    'drive/My Drive/TIF/train_new/TIF_AUG_AU_SI_ver1_fold_1.csv',\n","    'drive/My Drive/TIF/train_new/TIF_AUG_AU_SI_ver1_fold_2.csv',\n","]\n","test_csv_files = [\n","    'drive/My Drive/TIF/val_new/TIF_AUG_AU_SI_ver1_fold_0.csv',\n","    'drive/My Drive/TIF/val_new/TIF_AUG_AU_SI_ver1_fold_1.csv',\n","    'drive/My Drive/TIF/val_new/TIF_AUG_AU_SI_ver1_fold_2.csv',\n","]\n","\n","# Satır sayılarını belirle\n","train_sample_sizes = [40, 30, 25]  # t1: 20, t2: 30, t3: 15\n","test_sample_sizes = [5, 15, 20]  # v1: 10, v2: 15, v3: 5\n","\n","# Küçük CSV'leri oluştur\n","for i, (train_csv, test_csv) in enumerate(zip(train_csv_files, test_csv_files)):\n","    train_df = pd.read_csv(train_csv).head(train_sample_sizes[i])\n","    test_df = pd.read_csv(test_csv).head(test_sample_sizes[i])\n","\n","    # Yeni dosya isimleri\n","    train_sample_csv = f'drive/My Drive/TIF/sample_train_fold_{i}.csv'\n","    test_sample_csv = f'drive/My Drive/TIF/sample_test_fold_{i}.csv'\n","\n","    # Kaydet\n","    train_df.to_csv(train_sample_csv, index=False)\n","    test_df.to_csv(test_sample_csv, index=False)\n","\n","    print(f\"Küçük CSV'ler oluşturuldu: {train_sample_csv}, {test_sample_csv}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INafc28AokLr","executionInfo":{"status":"ok","timestamp":1743260387854,"user_tz":-180,"elapsed":5629,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"dd63a6a7-5299-401a-a967-ab953f7a59fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Küçük CSV'ler oluşturuldu: drive/My Drive/TIF/sample_train_fold_0.csv, drive/My Drive/TIF/sample_test_fold_0.csv\n","Küçük CSV'ler oluşturuldu: drive/My Drive/TIF/sample_train_fold_1.csv, drive/My Drive/TIF/sample_test_fold_1.csv\n","Küçük CSV'ler oluşturuldu: drive/My Drive/TIF/sample_train_fold_2.csv, drive/My Drive/TIF/sample_test_fold_2.csv\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset, random_split\n","from torchvision import transforms\n","import pandas as pd\n","from PIL import Image\n","from sklearn.metrics import f1_score, confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from timm import create_model\n","from sklearn.metrics import multilabel_confusion_matrix"],"metadata":{"id":"5n4Iewox-1QQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cmeft3V9EmQk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743260366911,"user_tz":-180,"elapsed":17999,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"c8f574d2-9c99-484b-8365-6c296ca3def9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset, random_split\n","from torchvision import transforms\n","import pandas as pd\n","from PIL import Image\n","import numpy as np\n","from sklearn.metrics import f1_score\n","from timm import create_model\n","\n","# Dataset Class\n","class AUDataset(Dataset):\n","    def __init__(self, csv_file, image_dir, transform=None):\n","        self.data = pd.read_csv(csv_file)\n","        self.image_dir = image_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.image_dir, str(self.data.iloc[idx]['fname']))\n","        image = Image.open(img_path).convert(\"RGB\")\n","        labels = torch.tensor(self.data.iloc[idx, 3:].values.astype('float32'))\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, labels, self.data.iloc[idx]['fname']\n","\n","# Model Class\n","class AUModel(nn.Module):\n","    def __init__(self, num_aus):\n","        super(AUModel, self).__init__()\n","        self.base_model = create_model('deit_small_patch16_224', pretrained=True)\n","        self.base_model.head = nn.Linear(self.base_model.head.in_features, num_aus)\n","\n","    def forward(self, x):\n","        return self.base_model(x)\n","\n","# Training Function\n","def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=3):\n","    best_model_state = None\n","    best_f1 = 0.0\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for inputs, labels, _ in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","        model.eval()\n","        val_preds, val_labels = [], []\n","        with torch.no_grad():\n","            for inputs, labels, _ in val_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                val_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n","                val_labels.extend(labels.cpu().numpy())\n","\n","        val_f1 = f1_score(np.array(val_labels) > 0.5, np.array(val_preds) > 0.5, average='macro')\n","        if val_f1 > best_f1:\n","            best_f1 = val_f1\n","            best_model_state = model.state_dict()\n","\n","    if best_model_state:\n","        model.load_state_dict(best_model_state)\n","    return model\n","\n","# Configurations\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","criterion = nn.BCEWithLogitsLoss()\n","num_aus = 8\n","all_results = []\n","\n","# Training and Testing\n","train_csvs = [f'drive/My Drive/TIF/sample_train_fold_{i}.csv' for i in range(3)]\n","test_csvs = [f'drive/My Drive/TIF/sample_test_fold_{i}.csv' for i in range(3)]\n","image_dir = 'drive/My Drive/TIF/CroppedFromPhotos/TIF_DB_Augmented'\n","\n","for fold, (train_csv, test_csv) in enumerate(zip(train_csvs, test_csvs)):\n","    train_dataset = AUDataset(train_csv, image_dir, transform)\n","    test_dataset = AUDataset(test_csv, image_dir, transform)\n","    train_size = int(0.8 * len(train_dataset))\n","    val_size = len(train_dataset) - train_size\n","    train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n","    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n","    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    model = AUModel(num_aus).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","    model = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=3)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for inputs, _, fnames in test_loader:\n","            inputs = inputs.to(device)\n","            outputs = torch.sigmoid(model(inputs)).cpu().numpy()\n","            for fname, pred in zip(fnames, outputs):\n","                all_results.append([fname] + pred.tolist())\n","\n","# Remove duplicates based on 'fname'\n","results_df = pd.DataFrame(all_results, columns=['fname'] + [f'AU{i+1}_prob' for i in range(num_aus)])\n","results_df = results_df.drop_duplicates(subset=['fname'])\n","results_df.to_csv(\"final_predictions.csv\", index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqAGD4eG-_7Q","executionInfo":{"status":"ok","timestamp":1743260990366,"user_tz":-180,"elapsed":100002,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"9572babf-9d7f-451e-b48f-ac4b0aa38c1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["au_columns = ['AU1', 'AU2', 'AU3', 'AU4', 'AU6', 'AU9', 'AU12', 'AU20']"],"metadata":{"id":"bpVuFN_yQZRh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FWSqcd9fcjvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Timport pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","# Sonuçları yükle\n","results_df = pd.read_csv(\"final_predictions.csv\")\n","true_labels_df = pd.read_csv(\"tif_train.csv\")\n","\n","\n","# Gerçek değerleri ve tahminleri ayır\n","true_labels = results_df[[f'AU{i+1}_true' for i in range(num_aus)]].values\n","pred_labels = results_df[[f'AU{i+1}_pred' for i in range(num_aus)]].values\n","\n","\n","# Gerçek etiketleri fname ile eşleştir\n","merged_df = results_df.merge(true_labels_df, on='fname', suffixes=('_pred', ''))\n","au_columns = ['AU1', 'AU2', 'AU3', 'AU4', 'AU6', 'AU9', 'AU12', 'AU20']\n","\n","# Gerçek değerleri ve tahminleri ayır\n","true_labels = merged_df[au_columns].values\n","pred_labels = results_df[[f'AU{i+1}_pred' for i in range(num_aus)]].values\n","\n","# Her AU için confusion matrix çiz\n","for i, au in enumerate(au_columns):\n","    cm = confusion_matrix(true_labels[:, i], pred_labels[:, i])\n","    plt.figure(figsize=(5, 4))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Neg\", \"Pos\"], yticklabels=[\"Neg\", \"Pos\"])\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"Actual\")\n","    plt.title(f\"Confusion Matrix for {au}\")\n","    plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"zoenV3hSbTOz","executionInfo":{"status":"error","timestamp":1743261078932,"user_tz":-180,"elapsed":71,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"5be2902b-8f13-436c-d754-78a7b38959a5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"\"None of [Index(['AU1_true', 'AU2_true', 'AU3_true', 'AU4_true', 'AU5_true', 'AU6_true',\\n       'AU7_true', 'AU8_true'],\\n      dtype='object')] are in the [columns]\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-83d5768939f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Gerçek değerleri ve tahminleri ayır\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'AU{i+1}_true'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_aus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'AU{i+1}_pred'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_aus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['AU1_true', 'AU2_true', 'AU3_true', 'AU4_true', 'AU5_true', 'AU6_true',\\n       'AU7_true', 'AU8_true'],\\n      dtype='object')] are in the [columns]\""]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","# Sonuçları yükle\n","results_df = pd.read_csv(\"final_predictions.csv\")\n","true_labels_df = pd.read_csv(\"tif_train.csv\")\n","\n","# Gerçek etiketleri fname ile eşleştir\n","merged_df = results_df.merge(true_labels_df, on='fname', suffixes=('_pred', ''))\n","num_aus = 8\n","\n","# Gerçek değerleri ve tahminleri ayır\n","true_labels = merged_df[[f'AU{i+1}' for i in range(num_aus)]].values\n","pred_labels = (merged_df[[f'AU{i+1}_prob' for i in range(num_aus)]].values > 0.5).astype(int)\n","\n","# Her AU için confusion matrix çiz\n","for i in range(num_aus):\n","    cm = confusion_matrix(true_labels[:, i], pred_labels[:, i])\n","    plt.figure(figsize=(5, 4))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Neg\", \"Pos\"], yticklabels=[\"Neg\", \"Pos\"])\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"Actual\")\n","    plt.title(f\"Confusion Matrix for AU{i+1}\")\n","    plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"8LgQSAq2brlf","executionInfo":{"status":"error","timestamp":1743260758315,"user_tz":-180,"elapsed":106,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"57236c07-1b16-4a26-db87-4ffec11aea29"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"\"['AU5', 'AU7', 'AU8'] not in index\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-6ed2b92f74f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Gerçek değerleri ve tahminleri ayır\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'AU{i+1}'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_aus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'AU{i+1}_prob'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_aus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['AU5', 'AU7', 'AU8'] not in index\""]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import torch\n","import numpy as np\n","\n","# Confusion matrix display function for subplot\n","def plot_confusion_matrix_subplot(true_labels, predictions, classes, ax):\n","    cm = confusion_matrix(true_labels, predictions)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n","    disp.plot(cmap=plt.cm.Blues, ax=ax)\n","    ax.set_title(f'Confusion Matrix')\n","\n","# Test phase to collect predictions and true labels\n","test_preds, test_labels = [], []\n","model.eval()  # Set the model to evaluation mode\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs = inputs.to(device)\n","        outputs = torch.sigmoid(model(inputs))  # Sigmoid output for multi-label classification\n","        preds = (outputs > 0.5).cpu().numpy()  # Apply threshold of 0.5 for binary classification\n","\n","        # Collect predictions and true labels\n","        test_preds.extend(preds)\n","        test_labels.extend(labels.cpu().numpy())\n","\n","# Convert to numpy arrays for sklearn compatibility\n","test_preds = np.array(test_preds)\n","test_labels = np.array(test_labels)\n","\n","# Set up subplot grid (4 columns)\n","num_classes = test_preds.shape[1]\n","ncols = 4\n","nrows = (num_classes + ncols - 1) // ncols  # Calculate number of rows needed\n","\n","fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, nrows * 4))\n","axes = axes.flatten()  # Flatten the axes array for easier indexing\n","\n","# Plot confusion matrices in subplots\n","for i in range(num_classes):\n","    ax = axes[i]\n","    plot_confusion_matrix_subplot(test_labels[:, i], test_preds[:, i], classes=[0, 1], ax=ax)\n","\n","    # Adjust titles for each subplot\n","    ax.set_title(f'Class: {au_columns[i]}')\n","\n","# Remove any unused subplots\n","for j in range(num_classes, len(axes)):\n","    axes[j].axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"XYMcGAtAEmm_","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1743260569069,"user_tz":-180,"elapsed":134,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"e62079a9-1055-4008-9e4d-e327f44f4c2e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-84a6ba077fdf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sigmoid output for multi-label classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Compute metrics for each Action Unit (AU)\n","results = []  # To store metrics for each AU\n","\n","for i in range(test_preds.shape[1]):  # Loop through each AU\n","    true_positive = np.sum((test_labels[:, i] == 1) & (test_preds[:, i] == 1))  # True positives\n","    false_positive = np.sum((test_labels[:, i] == 0) & (test_preds[:, i] == 1))  # False positives\n","    false_negative = np.sum((test_labels[:, i] == 1) & (test_preds[:, i] == 0))  # False negatives\n","    true_negative = np.sum((test_labels[:, i] == 0) & (test_preds[:, i] == 0))  # True negatives\n","\n","    total_samples = true_positive + false_positive + false_negative + true_negative  # Total samples for the AU\n","\n","    # Calculate Recall (True Positive Rate)\n","    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n","\n","    results.append({\n","        \"AU\": au_columns[i],\n","        \"Total Samples\": total_samples,\n","        \"Correctly Predicted\": true_positive + true_negative,\n","        \"Wrong Prediction\": false_positive + false_negative,\n","        \"Recall (%)\": recall * 100  # Recall as a percentage\n","    })\n","\n","# Convert results to a DataFrame for better visualization\n","results_df = pd.DataFrame(results)\n","\n","# Print the results as a table\n","print(results_df)\n","\n","# Optionally, save the results to a CSV file\n","results_df.to_csv(\"AU_metrics_total.csv\", index=False)"],"metadata":{"id":"XMLIR1ejbu2i","executionInfo":{"status":"ok","timestamp":1743073457860,"user_tz":-180,"elapsed":52,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4955c4cf-791e-4c5b-e2e4-59c29bd82b07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     AU  Total Samples  Correctly Predicted  Wrong Prediction  Recall (%)\n","0   AU1            369                  231               138   52.222222\n","1   AU2            369                  269               100    9.090909\n","2   AU3            369                  294                75   88.271605\n","3   AU4            369                  314                55   77.777778\n","4   AU6            369                  308                61   77.777778\n","5   AU9            369                  314                55   64.814815\n","6  AU12            369                  285                84   39.259259\n","7  AU20            369                  306                63   97.530864\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","# Convert to numpy arrays and apply threshold\n","test_labels_array = np.array(test_labels) > 0.5\n","test_preds_array = np.array(test_preds) > 0.5\n","\n","# Calculate overall F1 score (macro-average across all AUs)\n","overall_f1 = f1_score(test_labels_array, test_preds_array, average='macro')\n","\n","# Display the overall F1 score\n","print(f\"Overall F1 Score (Macro-Average): {overall_f1:.4f}\")"],"metadata":{"id":"sQqbuaCnHhSM","executionInfo":{"status":"ok","timestamp":1743073528432,"user_tz":-180,"elapsed":42,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3eb0cd3-ad3c-4c1f-c96a-2acf4a44bc72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overall F1 Score (Macro-Average): 0.6666\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Train CSV dosyalarının yollarını listeleyin\n","train_csv_files = [\n","    'drive/My Drive/TIF/train_new/TIF_AUG_AU_SI_ver1_fold_0.csv',\n","    'drive/My Drive/TIF/train_new/TIF_AUG_AU_SI_ver1_fold_1.csv',\n","    'drive/My Drive/TIF/train_new/TIF_AUG_AU_SI_ver1_fold_2.csv',\n","]\n","\n","# Tüm CSV'leri birleştirin\n","\n","train_data = pd.concat([pd.read_csv(csv_file) for csv_file in train_csv_files], ignore_index=True)\n","\n","# Duplike satırları kaldırın\n","train_data_cleaned = train_data.drop_duplicates()\n","\n","# Yeni temizlenmiş veriyi kaydedin\n","train_data_cleaned.to_csv('combined_train_data_tif.csv', index=False)\n","\n","print(f\"Orijinal veri sayısı: {len(train_data)}, Temizlenmiş veri sayısı: {len(train_data_cleaned)}\")\n"],"metadata":{"id":"utnDWbvqEmpT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742994932634,"user_tz":-180,"elapsed":31,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"af41e811-157d-42fe-a08c-af7e239f6795"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Orijinal veri sayısı: 2340, Temizlenmiş veri sayısı: 1170\n"]}]},{"cell_type":"code","source":["pred = pd.read_csv(\"all_test_predictions_with_val.csv\")\n","actual = pd.read_csv(\"combined_train_data_tif.csv\")\n","pred = pred.replace({True: 1, False: 0})\n","columns = ['fname'] + [col for col in pred.columns if col != 'fname']\n","pred = pred[columns]\n","pred.to_csv('pred.csv', index=False)"],"metadata":{"id":"-rsLwxVAbo7b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742994932668,"user_tz":-180,"elapsed":30,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"231bae5c-5208-47c5-df4e-17b10482876e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-ce5656259ed3>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  pred = pred.replace({True: 1, False: 0})\n"]}]},{"cell_type":"code","source":["predictions = pd.read_csv(\"pred.csv\")\n","common_rows = pd.merge(predictions, actual)\n","print(f\"Common rows: {len(common_rows)}\")"],"metadata":{"id":"yaCZ-FoGbo9j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742994932701,"user_tz":-180,"elapsed":29,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"c26b6386-1921-4773-d57c-5e912ce3d5a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Common rows: 99\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Train CSV dosyalarının yollarını listeleyin\n","train_csv_files = [\n","    'drive/My Drive/TIF/val_new/TIF_AUG_AU_SI_ver1_fold_0.csv',\n","    'drive/My Drive/TIF/val_new/TIF_AUG_AU_SI_ver1_fold_1.csv',\n","    'drive/My Drive/TIF/val_new/TIF_AUG_AU_SI_ver1_fold_2.csv',\n","]\n","# Tüm CSV'leri birleştirin\n","\n","train_data = pd.concat([pd.read_csv(csv_file) for csv_file in train_csv_files], ignore_index=True)\n","\n","# Duplike satırları kaldırın\n","train_data_cleaned = train_data.drop_duplicates()\n","\n","# Yeni temizlenmiş veriyi kaydedin\n","train_data_cleaned.to_csv('tif_train.csv', index=False)\n","\n","print(f\"Orijinal veri sayısı: {len(train_data)}, Temizlenmiş veri sayısı: {len(train_data_cleaned)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKd_hbLQEuKg","executionInfo":{"status":"ok","timestamp":1743164395054,"user_tz":-180,"elapsed":89,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"4483e7cd-3d16-43b7-eb00-877b4b0f1d22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Orijinal veri sayısı: 1170, Temizlenmiş veri sayısı: 1170\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Train CSV dosyalarının yollarını listeleyin\n","train_csv_files = [\n","    'drive/My Drive/TIF/train_new/TIF_AUG_AU_SI_ver1_fold_0.csv',\n","    'drive/My Drive/TIF/train_new/TIF_AUG_AU_SI_ver1_fold_1.csv',\n","    'drive/My Drive/TIF/train_new/TIF_AUG_AU_SI_ver1_fold_2.csv',\n","]\n","# Tüm CSV'leri birleştirin\n","\n","train_data = pd.concat([pd.read_csv(csv_file) for csv_file in train_csv_files], ignore_index=True)\n","\n","# Duplike satırları kaldırın\n","train_data_cleaned = train_data.drop_duplicates()\n","\n","# Yeni temizlenmiş veriyi kaydedin\n","train_data_cleaned.to_csv('tif_test.csv', index=False)\n","\n","print(f\"Orijinal veri sayısı: {len(train_data)}, Temizlenmiş veri sayısı: {len(train_data_cleaned)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOaecIwFsav3","executionInfo":{"status":"ok","timestamp":1743164417387,"user_tz":-180,"elapsed":70,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"5c0cbe42-ff6d-421e-dad3-86a674483cb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Orijinal veri sayısı: 2340, Temizlenmiş veri sayısı: 1170\n"]}]},{"cell_type":"code","source":["final_predictions.to_csv('/content/drive/My Drive/TIF/all_test_predictions_with_val.csv', index=False)\n"],"metadata":{"id":"SQBgQQJdkers"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# Google Drive'ı bağlayın\n","drive.mount('/content/drive')\n","\n","# Fotoğrafları saymak istediğiniz klasör yolu\n","folder_path = 'drive/My Drive/TIF/CroppedFromPhotos/TIF_DB_Augmented'  # Kendi klasör yolunuzu yazın\n","\n","# Desteklenen resim formatları\n","image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']\n","\n","# Klasördeki resimleri say\n","image_count = 0\n","for root, dirs, files in os.walk(folder_path):\n","    for file in files:\n","        if any(file.lower().endswith(ext) for ext in image_extensions):\n","            image_count += 1\n","\n","print(f\"Klasör ve alt klasörlerde toplam {image_count} resim dosyası bulundu.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55ChCVtfgXt-","executionInfo":{"status":"ok","timestamp":1742986471658,"user_tz":-180,"elapsed":2063,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"20f6bd05-b79f-47e0-c1e9-caf53e1742bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Klasör ve alt klasörlerde toplam 1179 resim dosyası bulundu.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# CSV dosyasını oku\n","df = pd.read_csv(\"/content/drive/My Drive/TIF/all_test_predictions_with_val.csv\")  # CSV dosyanızın adını yazın\n","\n","# AU sütunlarını belirle\n","au_columns = ['AU1', 'AU2', 'AU3', 'AU4', 'AU6', 'AU9', 'AU12', 'AU20']\n","\n","# True/False değerlerini 1/0'a dönüştür\n","for col in au_columns:\n","    df[col] = df[col].astype(int)  # True->1, False->0'a dönüşür\n","\n","# Değiştirilmiş veriyi yeni bir CSV dosyasına kaydet\n","df.to_csv('yeni_dosya_adı.csv', index=False)\n","\n","print(\"Dönüştürme tamamlandı. Yeni dosya oluşturuldu.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8ZIcDLvFuAl","executionInfo":{"status":"ok","timestamp":1742986893715,"user_tz":-180,"elapsed":25,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"243cde05-2c6a-4d32-aa37-8eb6a5a7f806"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dönüştürme tamamlandı. Yeni dosya oluşturuldu.\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('yeni_dosya_adı.csv')\n"],"metadata":{"id":"Tdt8fGMWHKDu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["1016+1106+1178"],"metadata":{"id":"D7W-cxrjHd-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df[['AU1', 'AU2', 'AU3', 'AU4', 'AU6', 'AU9', 'AU12', 'AU20']].sum())  # Pozitif örnek sayılarını gösterir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VPHxnKaHeAu","executionInfo":{"status":"ok","timestamp":1742989389730,"user_tz":-180,"elapsed":5,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"6b95f6eb-6ecc-45da-d5e4-86e03b0dcff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AU1     621\n","AU2     174\n","AU3     592\n","AU4     429\n","AU6     809\n","AU9     244\n","AU12    378\n","AU20    584\n","dtype: int64\n"]}]},{"cell_type":"code","source":["621/1170\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c50FOhzZHeCx","executionInfo":{"status":"ok","timestamp":1742987176749,"user_tz":-180,"elapsed":7,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"a4248876-1fcd-4be5-b796-141eb963afb3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5307692307692308"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["df['AU2'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"xwSJCIaaLxf9","executionInfo":{"status":"ok","timestamp":1742988165908,"user_tz":-180,"elapsed":12,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"9fcd105c-1214-487a-f0fd-b30a1c0dabf3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AU2\n","0    996\n","1    174\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>AU2</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>996</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>174</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["acsv_files = [\n","    'drive/My Drive/TIF/train/TIF_AUG_AU_SI_ver1_fold_0.csv',\n","    'drive/My Drive/TIF/train/TIF_AUG_AU_SI_ver1_fold_1.csv',\n","    'drive/My Drive/TIF/train/TIF_AUG_AU_SI_ver1_fold_2.csv',\n","]\n","bcsv_files = [\n","    'drive/My Drive/TIF/val/TIF_AUG_AU_SI_ver1_fold_0.csv',\n","    'drive/My Drive/TIF/val/TIF_AUG_AU_SI_ver1_fold_1.csv',\n","    'drive/My Drive/TIF/val/TIF_AUG_AU_SI_ver1_fold_2.csv',\n","]"],"metadata":{"id":"Ec4FKBEXWFJM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Train dosyalarındaki toplam satır sayısı\n","train_row_counts = []\n","for csv_file in acsv_files:\n","    df = pd.read_csv(csv_file)\n","    train_row_counts.append(len(df))\n","    print(f\"{csv_file}: {len(df)} satır\")\n","\n","total_train_rows = sum(train_row_counts)\n","print(f\"\\nToplam train satır sayısı: {total_train_rows}\")\n","\n","# Test dosyalarındaki toplam satır sayısı\n","test_row_counts = []\n","for csv_file in bcsv_files:\n","    df = pd.read_csv(csv_file)\n","    test_row_counts.append(len(df))\n","    print(f\"{csv_file}: {len(df)} satır\")\n","\n","total_test_rows = sum(test_row_counts)\n","print(f\"\\nToplam test satır sayısı: {total_test_rows}\")\n","\n","# Tüm veri setindeki toplam satır sayısı\n","print(f\"\\nTüm veri setindeki toplam satır sayısı: {total_train_rows + total_test_rows}\")"],"metadata":{"id":"921Rs2pFXWWY","executionInfo":{"status":"ok","timestamp":1742992028696,"user_tz":-180,"elapsed":67,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"ff1ff57b-9855-4f2b-dc9a-d004cb8873e1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["drive/My Drive/TIF/train/TIF_AUG_AU_SI_ver1_fold_0.csv: 774 satır\n","drive/My Drive/TIF/train/TIF_AUG_AU_SI_ver1_fold_1.csv: 783 satır\n","drive/My Drive/TIF/train/TIF_AUG_AU_SI_ver1_fold_2.csv: 801 satır\n","\n","Toplam train satır sayısı: 2358\n","drive/My Drive/TIF/val/TIF_AUG_AU_SI_ver1_fold_0.csv: 405 satır\n","drive/My Drive/TIF/val/TIF_AUG_AU_SI_ver1_fold_1.csv: 396 satır\n","drive/My Drive/TIF/val/TIF_AUG_AU_SI_ver1_fold_2.csv: 378 satır\n","\n","Toplam test satır sayısı: 1179\n","\n","Tüm veri setindeki toplam satır sayısı: 3537\n"]}]},{"cell_type":"code","source":["801+378"],"metadata":{"id":"hokO-_aSZS4T","executionInfo":{"status":"ok","timestamp":1742991783885,"user_tz":-180,"elapsed":44,"user":{"displayName":"Beyza Nur Keskin","userId":"15346924660563692244"}},"outputId":"9fc272f9-f23c-4f9a-ca0e-4ba07f582dad","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1179"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":[],"metadata":{"id":"nippnuQeZz8y"},"execution_count":null,"outputs":[]}]}
